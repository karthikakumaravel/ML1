# -*- coding: utf-8 -*-
"""knn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CIJvZrd49X4iqIyrlq41jpjKnzJlUOo-
"""

to impove model accuracy-->cross validation

"""knn

**CROSS VALIDATION**
hold out
70 30,60 40 testing,training
leave one out
leaving one section and training all and soo on
k-folder
1 st folder used for testing the data,and remaining is used for training the data

grid search
   ->to tune the hyper parameter
   ->to identify the best fiting models
   ->
"""

parameter ->to train and test the model,we are passing parameter
hyperparameter -> to tune and define the model

from sklearn.neighbors import KNeighborsClassifier
import pandas as pd

# Loading data
df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')
df.head()

df.isnull().sum()

df.dropna(subset=["Age"],axis=0,inplace=True)
df

df.dropna(subset=["Cabin"],axis=0,inplace=True)
df

df.isnull().sum()



x = df.drop('Classification',axis=1).values
y = df['Classification'].values
print("Entire dataset is\n",df)
print("\n X array is\n",x)
print("\n Y array is\n",y)
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(x, y)
# Predict on value which model has not seen before
z=knn.predict([[3,7]])
print("The predicted Output for (3,7) is",z)