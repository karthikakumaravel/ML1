# -*- coding: utf-8 -*-
"""NAIVEBAYES.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_h4P3ejxUzkFqRcjn6JA62Ee9-loMMOY
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

data=pd.read_csv('/content/heart (1).csv')
data.head()

y=data['output']
X=data.drop('output',axis=1)
#print(X.head())
print(y)

#split the data into training and testing data sets
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.8,random_state=42)
scaler=StandardScaler()
scale=scaler.fit(X_train)
X_train=scale.transform(X_train)
X_test=scale.transform(X_test)

from sklearn.naive_bayes import GaussianNB
train_y=data["output"]
train_x=data[['age','sex','cp','trtbps','chol','fbs','restecg','exng','oldpeak','slp','caa','thall']]

from sklearn.model_selection import train_test_split
train_data,val_data,train_target,val_target=train_test_split(train_x,train_y,train_size=0.8)

model=GaussianNB()
model.fit(train_data,train_target)
val_pred=model.predict(val_data)

res=pd.DataFrame({'Actual': val_target,'Predicted':val_pred})
print(res)

print('model accuracy score :(0:0.4f)',format(accuracy_score(val_target,val_pred)*100)+"%")

# Evaluate the model
from sklearn import metrics

# Accuracy
accuracy = metrics.accuracy_score(val_target,val_pred)
print("Accuracy:", accuracy)

# Precision, Recall, and F1-Score for each class
precision, recall, f1_score, support = metrics.precision_recall_fscore_support(val_target,val_pred,labels=model.classes_)
for i, class_label in enumerate(model.classes_):
    print(f"Class {class_label}:")
    print(f"  Precision: {precision[i]}")
    print(f"  Recall: {recall[i]}")
    print(f"  F1-Score: {f1_score[i]}")
    print(f"  Support: {support[i]}\n")

# Confusion Matrix
confusion_matrix = metrics.confusion_matrix(val_target,val_pred)
print("Confusion Matrix:")
print(confusion_matrix)

# Plot a heatmap of the confusion matrix
plt.figure(figsize=(4, 4))
sns.heatmap(confusion_matrix, annot=True, fmt="d", cmap="inferno", xticklabels=model.classes_, yticklabels=model.classes_)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()